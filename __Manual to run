## needed Libraries
    1- Tensorflow-gpu v1.12.0
    2- ai2thor v 2.2.0
    3- numpy   latest version 1.18.1
    4- pandas v 1.0.0
    ### Hint
    There be additional related to Main Library

### Steps to run the code
    1- load the Autoencoder weights
    file name: autoencoder
        class Network(object):
            #### Create model
21-            def __init__(self):
22-           self.save_path = '### YOUR PATH to AUTOENCODER WEIGHTS###/CNN_AE.ckpt'

    3- setting the directory where the training weights to be save -> dir = /your_directory/

    2- The model was trained on Environment "FloorPlan225" which is the default in the Environment Class
        ### Any changes to the Environment.py specially Scene and Actions, those changes need to be done also in Environment_top_view.py file

Running file in any folder those settings need to be modified
running files path:
for playing the trajectory:
    playing/trajectory_plotting_images_only.py
    playing/trajectory_plotting_images_pos.py
    playing/trajectory_plotting_shaped_reward_only.py

for training and evalation shaped reward only: 
    Agent_shaped_reward_only/DRQN_HER_Training.py

for training and evalation images and position images only: 
    Agent_image_only/DRQN_HER_Training.py

for training and evalation images and positions images and positions: 
    Agent_shaped_reward_wiz_her_images_and_postions/DRQN_HER_Training.py

    3- Specify which reward type to use in DRQN_HER_Training.py -> reward =  ["shaped"],["sparse"]


lines 25  For Random Agent initialization from random position only -> random_init_position = True
                                                                    random_init_pose = False

lines 22 Random Agent initialization from random position and Pose -> random_init_position = False
                                                                        random_init_pose = True

    6- Top enable or disable the top view render -> top_view = True/False  # displaying top-view

    7- Input-Size Parameter is the number of the size of the input to the LSTM is a vector of size 521
        - Autpencoder Latent-vector size = 512
        - agent position = 3
        - Number of Agent Actions = 3 latest set of action
        - #### if the number of the actions to be changed the number of the input size should also be changed ###

 DRQN_3_her_shaped_sequence -> DRQN with images and positions with shaped reward and HER ###### DONE

 DRQN_3_her_shaped_sequence_images_only -> DRQN with images and without positions with shaped reward and HER ###### DONE

 DRQN_3_her_sparse_sequence -> DRQN with images and positions with sparse reward and HER

 DRQN_3_her_sparse_sequence_images_only -> DRQN with images and without positions with sparse reward and HER ###### DONE


